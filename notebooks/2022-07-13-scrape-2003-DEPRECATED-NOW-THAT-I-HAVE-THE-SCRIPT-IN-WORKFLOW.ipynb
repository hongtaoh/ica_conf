{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651d9352",
   "metadata": {},
   "source": [
    "## Aim: (This page is useless now. Using `2022-07-09-define-all-necessary-defs` is enough.)\n",
    "\n",
    "It seems that I can scrape 2004 website without a problem but 2003 has an issue.\n",
    "\n",
    "### Conclude\n",
    "\n",
    "Solved. using `iterators[-2].click()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964d4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1faa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_on_search_papers():\n",
    "    search_papers = wait.until(EC.element_to_be_clickable((\n",
    "        By.CSS_SELECTOR, \n",
    "        \"div.menu_item__icon_text_window__text > a.mainmenu_text\"\n",
    "    )))\n",
    "    search_papers.click()\n",
    "\n",
    "def get_papers():\n",
    "    \"\"\"\n",
    "    get all paper elements in the current page\n",
    "    \"\"\"\n",
    "    papers = driver.find_elements(\n",
    "        By.CSS_SELECTOR, 'tr.worksheet_window__row__light, tr.worksheet_window__row__dark'\n",
    "    )\n",
    "    return papers\n",
    "\n",
    "def get_paper_meta(paper, year, paper_meta_dict_list):\n",
    "    \"\"\"\n",
    "    get paper index, paper title, and paper_type\n",
    "        the author names can be found here but I'll collect later in the view page\n",
    "    \"\"\"\n",
    "    idx = paper.find_element(\n",
    "        By.CSS_SELECTOR, 'td[title=\"##\"]').text\n",
    "    paper_id = year + '-' + idx\n",
    "    # summary elements:\n",
    "    summary = paper.find_element(\n",
    "        By.CSS_SELECTOR, 'td[title=\"Summary\"]'\n",
    "    )\n",
    "    title = summary.find_element(\n",
    "        By.CSS_SELECTOR, 'a.search_headingtext'\n",
    "    ).text\n",
    "    submission_type = summary.find_element(\n",
    "        By.CSS_SELECTOR, 'td[style=\"padding: 5px;\"]'\n",
    "    ).text\n",
    "    paper_meta_dict = {\n",
    "        'Paper ID': paper_id,\n",
    "        'Title': title,\n",
    "        'Type': submission_type\n",
    "    }\n",
    "    # update the dict list\n",
    "    paper_meta_dict_list.append(paper_meta_dict)\n",
    "    return paper_meta_dict\n",
    "\n",
    "def open_view(paper):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        paper element\n",
    "    Aim:\n",
    "        open a new window and click 'view'\n",
    "    \"\"\"\n",
    "    action = paper.find_element(\n",
    "        By.CSS_SELECTOR, 'td[title=\"Action\"]'\n",
    "    )\n",
    "    view_link_e = action.find_element(\n",
    "                By.CSS_SELECTOR, \"li.action_list > a.fieldtext\"\n",
    "            )\n",
    "    view_link = view_link_e.get_attribute('href')\n",
    "    driver.execute_script(\"window.open('');\")\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    driver.get(view_link)\n",
    "\n",
    "def get_title_to_check(paper_meta_dict_list):\n",
    "    # there are two 'tr.header font.headingtext'\n",
    "    # title is the second one\n",
    "    headingtexts = driver.find_elements(\n",
    "        By.CSS_SELECTOR, 'tr.header font.headingtext'\n",
    "    )\n",
    "    title_to_check = headingtexts[1].text\n",
    "    # update the most recent paper_meta_dict_list\n",
    "    paper_meta_dict_list[-1]['Title to Check'] = title_to_check\n",
    "    return title_to_check\n",
    "\n",
    "\n",
    "def get_authors(paper_meta_dict, author_dict_list):\n",
    "    paper_id, title = paper_meta_dict['Paper ID'], paper_meta_dict['Title']\n",
    "    # note that authors_e will return a list since there might be multiple authors\n",
    "    authors = driver.find_elements(\n",
    "        By.CSS_SELECTOR, 'a.search_fieldtext_name'\n",
    "    )\n",
    "    for author in authors:\n",
    "        author_idx = authors.index(author) + 1\n",
    "        authorNum = len(authors)\n",
    "        author_elements = author.text.split(' (')\n",
    "        author_name = author_elements[0]\n",
    "        # doc: https://docs.python.org/3.4/library/stdtypes.html?highlight=strip#str.rstrip\n",
    "        # some don't contain '()', i.e., affiliation info\n",
    "        try:\n",
    "            author_aff = author_elements[1].rstrip(')')\n",
    "        except:\n",
    "            author_aff = np.nan\n",
    "        author_dict = {\n",
    "            'Paper ID': paper_id,\n",
    "            'Paper Title': title,\n",
    "            'Number of Authors': authorNum,\n",
    "            'Author Position': author_idx,\n",
    "            'Author Name': author_name,\n",
    "            'Author Affiliation': author_aff,\n",
    "        }\n",
    "        author_dict_list.append(author_dict)\n",
    "\n",
    "def get_abstract(paper_meta_dict_list):\n",
    "    # abstract\n",
    "    abstract = driver.find_element(\n",
    "        By.CSS_SELECTOR, 'blockquote.tight > font.fieldtext'\n",
    "    ).text\n",
    "    paper_meta_dict_list[-1]['Abstract'] = abstract\n",
    "    return abstract\n",
    "\n",
    "def scrape_one_page(year, page_num):\n",
    "    papers = get_papers()\n",
    "    for paper in papers[0:1]:\n",
    "        paper_idx = papers.index(paper) + 1\n",
    "        paper_meta_dict = get_paper_meta(paper, year, paper_meta_dict_list)\n",
    "        open_view(paper)\n",
    "        get_title_to_check(paper_meta_dict_list)\n",
    "        get_authors(paper_meta_dict, author_dict_list)\n",
    "        get_abstract(paper_meta_dict_list)\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        print(f'Page {page_num} Paper {paper_idx} is done')\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574075e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nth-child(1) means there are two div.iterators, I only need one of the two\n",
    "def get_iterators():\n",
    "    iterators = driver.find_elements(\n",
    "        By.CSS_SELECTOR, \"div.iterator:nth-child(1) > form a.fieldtext\"\n",
    "    )\n",
    "    return iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f472bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://convention2.allacademic.com/one/ica/ica03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fb789db",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "driver.get(url)\n",
    "click_on_search_papers()\n",
    "paper_meta_dict_list = []\n",
    "author_dict_list = []\n",
    "iterators = get_iterators() # used to calculate total pages\n",
    "total_pages = int(iterators[-2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "820eeb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 10 Paper 1 is done\n",
      "page 10 is done\n",
      "Page 11 Paper 1 is done\n",
      "page 11 is done\n",
      "Page 12 Paper 1 is done\n",
      "page 12 is done\n",
      "Page 13 Paper 1 is done\n",
      "page 13 is done\n",
      "Page 14 Paper 1 is done\n",
      "page 14 is done\n",
      "Page 15 Paper 1 is done\n",
      "page 15 is done\n",
      "Page 16 Paper 1 is done\n",
      "page 16 is done\n",
      "Page 17 Paper 1 is done\n",
      "page 17 is done\n",
      "Page 18 Paper 1 is done\n",
      "page 18 is done\n",
      "Page 19 Paper 1 is done\n",
      "page 19 is done\n",
      "Page 20 Paper 1 is done\n",
      "page 20 is done\n"
     ]
    }
   ],
   "source": [
    "year = '2003'\n",
    "for i in range(10,total_pages+1):\n",
    "    page_num = i\n",
    "    if i > 12:\n",
    "        iterators = get_iterators()\n",
    "        iterators[-2].click()\n",
    "    iterators = get_iterators()\n",
    "    for j in iterators:\n",
    "        if (j.text == str(i)):\n",
    "            j.click()\n",
    "            break \n",
    "    scrape_one_page(year,page_num)\n",
    "    print(f'page {i} is done')\n",
    "    if i < total_pages - 1:\n",
    "        driver.refresh()\n",
    "    if i == total_pages - 1:\n",
    "        iterators = get_iterators()\n",
    "        iterators[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
