Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                 count
----------------  -------
all                     1
combine_all_data        1
total                   2

Select jobs to execute...

[Wed Oct 30 07:39:53 2024]
rule combine_all_data:
    input: ../data/interim/paper_df_2003_2004.csv, ../data/interim/paper_df_2005_2013.csv, ../data/interim/paper_df_2014_2018.csv, ../data/interim/interactive_paper_df_2014_2018.csv, ../data/interim/author_df_2003_2004.csv, ../data/interim/author_df_2005_2013.csv, ../data/interim/author_df_2014_2018.csv, ../data/interim/interactive_author_df_2014_2018.csv, ../data/interim/session_df_2014_2018.csv, ../data/interim/interactive_session_df_2014_2018.csv
    output: ../data/processed/papers.json, ../data/processed/authors.json, ../data/processed/sessions.json
    jobid: 1
    reason: Missing output files: ../data/processed/papers.json, ../data/processed/sessions.json, ../data/processed/authors.json
    resources: tmpdir=/var/folders/wx/xz5y_06d15q5pgl_mhv76c8r0000gn/T

[Wed Oct 30 07:39:55 2024]
Error in rule combine_all_data:
    jobid: 1
    input: ../data/interim/paper_df_2003_2004.csv, ../data/interim/paper_df_2005_2013.csv, ../data/interim/paper_df_2014_2018.csv, ../data/interim/interactive_paper_df_2014_2018.csv, ../data/interim/author_df_2003_2004.csv, ../data/interim/author_df_2005_2013.csv, ../data/interim/author_df_2014_2018.csv, ../data/interim/interactive_author_df_2014_2018.csv, ../data/interim/session_df_2014_2018.csv, ../data/interim/interactive_session_df_2014_2018.csv
    output: ../data/processed/papers.json, ../data/processed/authors.json, ../data/processed/sessions.json
    shell:
        python scripts/combine_all_data.py ../data/interim/paper_df_2003_2004.csv ../data/interim/paper_df_2005_2013.csv ../data/interim/paper_df_2014_2018.csv ../data/interim/interactive_paper_df_2014_2018.csv ../data/interim/author_df_2003_2004.csv ../data/interim/author_df_2005_2013.csv ../data/interim/author_df_2014_2018.csv ../data/interim/interactive_author_df_2014_2018.csv ../data/interim/session_df_2014_2018.csv ../data/interim/interactive_session_df_2014_2018.csv ../data/processed/papers.json ../data/processed/authors.json ../data/processed/sessions.json
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job combine_all_data since they might be corrupted:
../data/processed/papers.json
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-10-30T073952.997118.snakemake.log
